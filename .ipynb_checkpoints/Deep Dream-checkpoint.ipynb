{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dream\n",
    "More like weird dream.  \n",
    "<img src=\"images/deepdream.jpg\" width=\"500\" />  \n",
    "  \n",
    "  \n",
    "After training a CNN each of its layers act as a feature classifiers, deeper layers classify more complex features like eyes and even faces, shallower layers classify less complex features like edges or texture.  \n",
    "Having that in mind, if you manipulate the data in a given image to maximize the activations of the layer that classifies, let's say, eyes, Then this image is going to seem like it has so many eyes in it. This is basically the concept of deep dream.  \n",
    "# Plan of attack\n",
    "* Get a pretrained model (we'll use InceptionV3)\n",
    "* Feed an image through this model and get some layers' outputs\n",
    "* Maximize those ouputs WRT the image data\n",
    "\n",
    "Let's import important modules first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's define some helper functions\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "    img = 255*(img + 1.0)/2.0\n",
    "    return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "    display.display(Image.fromarray(np.array(img)))\n",
    "    \n",
    "img = Image.open(\"images/white.jpg\")\n",
    "show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained model\n",
    "We'll use the InceptionV3 model in the applications module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = tf.keras.applications.InceptionV3(include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose layers to maximize\n",
    "We could use one layer but let's get the general case and choose more than one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximize the activations of these layers\n",
    "names = ['mixed3']\n",
    "layers = [inc.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=inc.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximize activations WRT image\n",
    "First you need to have a well defined function to maximize.  \n",
    "Let's do that now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(img, model):\n",
    "  # Pass forward the image through the model to retrieve the activations.\n",
    "  # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "    if len(layer_activations) == 1:\n",
    "        layer_activations = [layer_activations]\n",
    "\n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return  tf.reduce_sum(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember we need to maximize, and that is not the default in tensorflow\n",
    "# we dont't want to subtract the gradient from the image, we want to add it\n",
    "# so let's define everything ourselvs\n",
    "\n",
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "        \n",
    "    # this decorator is used for performance purposes\n",
    "    @tf.function(\n",
    "      input_signature=(\n",
    "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "    )\n",
    "    def __call__(self, img, steps, step_size):\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "            \n",
    "            gradients = tape.gradient(loss, img)\n",
    "            \n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            img = img + gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "        \n",
    "        return loss, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's create an instance of that class\n",
    "deepdream = DeepDream(dream_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a function to make our lives easier\n",
    "def run_deep_dream(img, steps=100, step_size=0.01):\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    \n",
    "    step_size = tf.convert_to_tensor(step_size)\n",
    "    steps_remaining = steps\n",
    "    step = 0\n",
    "    \n",
    "    while steps_remaining:\n",
    "        if steps_remaining>100:\n",
    "            run_steps = tf.constant(100)\n",
    "        else:\n",
    "            run_steps = tf.constant(steps_remaining)\n",
    "        steps_remaining -= run_steps\n",
    "        step += run_steps\n",
    "\n",
    "        loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        show(deprocess(img))\n",
    "        print (\"Step {}, loss {}\".format(step, loss))\n",
    "\n",
    "\n",
    "    result = deprocess(img)\n",
    "    display.clear_output(wait=True)\n",
    "    show(result)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig = mpimg.imread(\"images/white.jpg\")\n",
    "dream_img = run_deep_dream(img=orig, \n",
    "                                  steps=100, step_size=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## noiiiiissse\n",
    "no body likes that. let's get rid of it.  \n",
    "But that is not the only problem though.\n",
    "* we have noise\n",
    "* we have low resolution\n",
    "* all the patterns appear at the same granularity\n",
    "\n",
    "one stone, three birds.  \n",
    "The stone is to apply gradient ascent at different scales. This will allow patterns generated at smaller scales to be incorporated into patterns generated at higher scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_SCALE = 1.30\n",
    "\n",
    "orig = mpimg.imread(\"images/white.jpg\")\n",
    "\n",
    "img = tf.constant(orig)\n",
    "base_shape = tf.shape(img)[:-1]\n",
    "float_base_shape = tf.cast(base_shape, tf.float32)\n",
    "\n",
    "for n in range(-2, 3):\n",
    "    new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
    "\n",
    "    img = tf.image.resize(img, new_shape).numpy()\n",
    "\n",
    "    img = run_deep_dream(img=img, steps=20, step_size=0.01)\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "img = tf.image.resize(img, base_shape)\n",
    "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
    "show(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome\n",
    "Now experement with different activation layers to see different patterns and share if you got anything interesting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
